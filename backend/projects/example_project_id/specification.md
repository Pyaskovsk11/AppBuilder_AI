---

## Памятка для frontend UX/UI разработчика

### 1. Ключевые принципы UX
- Вся работа строится вокруг итеративных циклов: пользователь видит результат, даёт обратную связь, система дорабатывает продукт.
- Важно визуализировать не только текущее состояние, но и историю изменений, итераций, стоимость LLM.
- Пользователь должен видеть прозрачную логику: какие задачи сейчас в работе, какие отчёты требуют внимания, что уже исправлено.
- Вся обратная связь пользователя (feedback) — триггер для нового цикла доработки, а не для полной перегенерации.
- Интерфейс должен быть лёгким, быстрым, с акцентом на прозрачность и контроль.

### 2. Основные UX-потоки
- Инициализация проекта (форма бизнес-идеи)
- Визуализация статуса проекта: статус, задачи, отчёты, история итераций, стоимость LLM
- Просмотр и фильтрация задач (по статусу, исполнителю, приоритету)
- Просмотр и фильтрация отчётов (по типу, severity)
- Панель обратной связи: пользователь может оставить комментарий/запрос на доработку (feedback)
- Просмотр Live Project Context (полный state.json)
- Просмотр и экспорт документации

### 3. API для фронтенда (FastAPI)
- POST `/projects/init` — создать проект
- POST `/projects/{project_id}/dispatch` — запустить/продолжить workflow
- GET `/projects/{project_id}/status` — получить статус, задачи, отчёты (поддерживает фильтры)
- GET `/projects/{project_id}/context` — получить весь Live Project Context
- POST `/projects/{project_id}/feedback` — отправить обратную связь (feedback)
- POST `/projects/{project_id}/docs` — сгенерировать документацию
- POST `/projects/{project_id}/export_notion` — экспорт в Notion
- POST `/projects/{project_id}/export_docs` — экспорт в Plane.so

### 4. Структура данных (state.json)
- `status`: string — статус проекта
- `iteration_count`: int — количество итераций
- `current_llm_cost`: float — стоимость LLM
- `tasks`: list — задачи (см. Task)
- `reports`: list — отчёты (см. Report)

#### Task
```json
{
  "id": "task-1",
  "description": "...",
  "status": "pending|in_progress|awaiting_review|completed|failed",
  "priority": 1,
  "assigned_to": "agent_name",
  "artifacts_produced": ["..."],
  "subtasks": [ ... ]
}
```
#### Report
```json
{
  "type": "qa_functional|security_audit|user_feedback",
  "severity": "low|medium|high|critical",
  "content": "...",
  "created_at": "...",
  "related_task": "..."
}
```

### 5. Best practices для UI
- Использовать Tailwind CSS для быстрой стилизации и адаптивности.
- Все фильтры должны быть интерактивными, с мгновенным откликом.
- Для истории итераций — timeline или stepper.
- Для отчётов — цветовая индикация severity, быстрый переход к связанным задачам.
- Для feedback — отдельная панель/модалка, всегда доступная пользователю.
- Для стоимости LLM — индикатор/прогресс-бар, предупреждение при приближении к лимиту.
- Для документации — markdown viewer с возможностью экспорта.
- Для интеграций (Notion, Plane.so) — кнопки экспорта, статус последней синхронизации.

### 6. UX-антипаттерны (чего избегать)
- Не скрывать ошибки и отчёты — пользователь должен видеть все проблемы.
- Не делать workflow «чёрным ящиком» — всегда показывать, что происходит.
- Не перегружать интерфейс деталями, но давать доступ к полному контексту по клику.
- Не блокировать пользователя на длительных операциях — использовать лоадеры, прогресс-бары.

---
### **Уточнения и добавления к спецификации**

Вот мои предложения, сгруппированные по разделам.

#### **1. Раздел "Описание"**
*   **Добавить:** "Платформа работает на основе **итеративных циклов самокоррекции**, а не по линейной модели 'водопада'."
    *   **Почему:** Это ключевое отличие и конкурентное преимущество. Важно зафиксировать его в самом начале.

#### **2. Раздел "Модели данных"**
Здесь есть критически важные дополнения для управления сложными процессами.

*   **Модель `Project`:**
    *   **Добавить:** `iteration_count: integer` — счетчик циклов исправлений. Это нужно для работы предохранителей, чтобы избежать бесконечных циклов.
    *   **Добавить:** `current_llm_cost: float` — счетчик стоимости вызовов LLM для данного проекта. Это важная бизнес-метрика.

*   **Модель `Task`:**
    *   **Уточнить:** `status` должен быть более гранулярным. Не просто "в работе", а `['pending', 'in_progress', 'awaiting_review', 'completed', 'failed']`.
    *   **Добавить:** `assigned_to: string (agent_name)` — четко указывает, какой агент отвечает за задачу.
    *   **Добавить:** `artifacts_produced: list[string]` — список ссылок на артефакты (файлы, записи в БД), которые создала эта задача. Это нужно для отслеживания результатов и отката изменений.

*   **Модель `Report`:**
    *   **Уточнить:** `type` должен быть перечислением (enum): `['qa_functional', 'security_audit', 'user_feedback']`.
    *   **Добавить:** `severity: string ('low', 'medium', 'high', 'critical')` — приоритезация отчетов для более умного планирования исправлений.

#### **3. Раздел "API-эндпоинты"**
*   **POST `/projects/{project_id}/run`:**
    *   **Переименовать в `POST /projects/{project_id}/dispatch`:** Слово `dispatch` лучше отражает суть того, что делает `PraisonAI Dispatcher` — он не просто "запускает", а "диспетчеризирует" задачи агентам.
*   **Добавить новый эндпоинт: `POST /projects/{project_id}/feedback`:**
    *   **Назначение:** Это эндпоинт для будущего, но его нужно заложить в архитектуру сейчас. Через него пользователь сможет дать обратную связь на сгенерированное приложение ("добавь поле 'телефон'"). Этот вызов создаст новый `Report` типа `user_feedback` и инициирует итеративный цикл доработки, а не генерацию с нуля.
    *   **Почему:** Это закладывает фундамент для самой важной функции после MVP — **итеративной доработки проекта**.

#### **4. Раздел "Ключевые функции"**
*   **Переименовать `auto_fixer` в `Self-Correction Cycle` (Цикл самокоррекции).**
    *   **Почему:** Это не отдельная функция, а **основной рабочий процесс** системы, включающий QA, аудит и повторный вызов разработчиков. Название должно отражать его системный характер.
*   **Добавить `Vectorized Codebase Indexing`:**
    *   **Почему:** Это неявная, но критически важная функция. Нужно явно указать, что система не просто хранит код, а создает и поддерживает его векторное представление для эффективного семантического поиска агентами.
*   **Добавить `LLM Cost Tracking and Limiting`:**
    *   **Почему:** Это важная бизнес-функция. Система должна не только считать, но и потенциально останавливать проекты, превысившие установленный лимит затрат.

---

### **Финальная версия спецификации с моими правками**

(Жирным выделены мои добавления и изменения)

## Название
AppBuilder AI

## Описание
Платформа для автоматизированной генерации, тестирования, аудита и документирования веб-приложений на основе бизнес-идеи пользователя. Использует иерархию AI-агентов, расширяемый набор инструментов и Live Project Context. **Платформа работает на основе итеративных циклов самокоррекции, а не по линейной модели "водопада".**

## Основные компоненты
- FastAPI backend (Python)
- PraisonAI Core (агенты, dispatcher, инструменты)
- Live Project Context (единый источник правды)
- Frontend (React, Tailwind CSS)
- Redis (кэширование)
- Docker-инфраструктура

## Модели данных

### Project
```json
{
  "id": "project-1",
  "core_mandate": "...",
  "status": "in_progress",
  "iteration_count": 0,
  "current_llm_cost": 0.0,
  "tasks": [...],
  "reports": [...]
}
```

### Task
```json
{
  "id": "task-1",
  "agent": "backend-dev",
  "description": "Реализовать API для постов",
  "status": "pending",
  "priority": 1,
  "dependencies": [],
  "assigned_to": "backend-dev",
  "artifacts_produced": ["app/models/post.rb", "app/controllers/posts_controller.rb"],
  "subtasks": [
    {"id": "task-1.1", "description": "Создать модель Post", "status": "pending"}
  ]
}
```

### Report
```json
{
  "type": "qa_functional",
  "severity": "medium",
  "content": "Тесты не проходят для PostsController.",
  "created_at": "2025-08-06T12:00:00Z",
  "related_task": "task-1"
}
```

## API-эндпоинты (основные)
- POST `/projects/init` — инициализация проекта
- POST `/projects/{project_id}/dispatch` — запуск/продолжение workflow агентов
  - **Пример запроса:**
    ```json
    {}
    ```
  - **Пример ответа:**
    ```json
    {"status": "workflow_started"}
    ```
- GET `/projects/{project_id}/status` — статус, задачи и отчёты
- GET `/projects/{project_id}/context` — Live Project Context
- POST `/projects/{project_id}/feedback` — итеративная доработка проекта по запросу пользователя
  - **Пример запроса:**
    ```json
    {"feedback": "Добавить поле 'телефон' в форму регистрации"}
    ```
  - **Пример ответа:**
    ```json
    {"status": "feedback_accepted", "report_id": "report-2"}
    ```


## Ключевые функции
- Генерация кода (backend, frontend, миграции)
- Генерация и запуск тестов (RSpec, test-generator)
- Аудит безопасности (Brakeman, security-auditor)
- **Self-Correction Cycle:**
  - Автоматический цикл: QA → Report → Auto-fixer → Developer → QA
  - Включает автоматическую генерацию задач на исправление по отчётам
  - **Реализовано: автоматизация цикла, генерация задач по отчётам**
- **Vectorized Codebase Indexing:**
  - Векторизация кода для семантического поиска и навигации агентами
  - **Реализовано: модуль vector_store, интеграция с context_manager**
- **LLM Cost Tracking and Limiting:**
  - Учёт стоимости вызовов LLM, автоматическое ограничение при превышении лимита
  - **Реализовано: лимит и учёт стоимости в dispatcher/context_manager**
- Генерация документации (doc-generator)
- MCP-агент для выгрузки документации в Plane.so
- Управление задачами с приоритетами, зависимостями, вложенностью
- Автоматизация анализа и создания задач на исправление

---

## Статус реализации и следующие задачи

### Реализовано:
- Базовая архитектура backend (FastAPI, PraisonAI Core, context_manager, dispatcher)
- Декларативная конфигурация агентов (agents.yaml)
- Модули: генерация задач, self-correction cycle, vector_store, учёт стоимости LLM
- Интеграция Plane.so (MCP-агент, экспорт документации)
- Расширенная структура state.json (поддержка вложенных задач, зависимостей, отчётов, стоимости)
- Покрытие ключевых модулей unit-тестами, стабильная инфраструктура тестирования
- Автоматизация генерации тестов и аудита для новых фич (подзадачи, интеграция с workflow)

### Следующие этапы и рекомендации по итогам ревью модулей:

#### 1. Фронтенд
- Реализация интерфейса (React + Tailwind CSS):
  - Визуализация статуса, задач, отчётов, стоимости LLM, истории итераций.
  - Панель обратной связи (feedback), фильтрация задач и отчётов.

#### 2. Расширение аналитики и бизнес-метрик
- Добавить новые метрики (количество feedback, среднее время реакции, эффективность исправлений).
- Визуализация аналитики на фронтенде.

#### 3. Интеграция с внешними платформами
- **Notion:** MCP-агент реализован, требуется:
  - Улучшить парсинг markdown → Notion blocks (поддержка форматирования, вложенности).
  - Добавить поддержку вложенных задач, связей между задачами и отчётами.
  - Расширить шаблоны для отчётов и задач.
- **Plane.so:** MCP-агент стабилен, покрыт тестами.
- **Confluence:** Требуется разработка MCP-агента по аналогии с Notion/Plane.

#### 4. Архитектурный рефакторинг и тесты
- Провести ревью архитектуры (структура модулей, потоки данных, точки расширения).
- Выделить общие компоненты для работы с внешними платформами (базовые MCP-агенты, шаблоны экспорта).
- Рефакторинг инструментов: унификация интерфейсов, улучшение тестируемости.
- Покрытие новых и изменённых модулей unit-тестами (особое внимание: интеграция с внешними платформами, self-correction cycle, vector_store).
- Подготовить подробную документацию для разработчиков:
  - Описание архитектуры, точек расширения, best practices по добавлению MCP-агентов и инструментов.
  - Примеры unit-тестов и шаблоны для новых модулей.

#### 5. Улучшения и TODO по итогам ревью модулей
- auto_fixer.py, test_generator.py: требуется интеграция с LLM или шаблонами (сейчас заглушки).
- vector_store.py: реализовать реальный семантический поиск и хранение векторных индексов (сейчас только интерфейс).
- doc_generator.py: расширить генерацию документации (архитектурные диаграммы, примеры API, связи между задачами и отчётами).
- mcp_notion_exporter: улучшить обработку ошибок, добавить тесты на edge-cases.
- mcp_plane_exporter: добавить тесты на обновление существующих страниц.

---

### Приоритетные задачи (roadmap)
1. Реализация полноценного фронтенда (React + Tailwind CSS)
2. Доработка MCP-агента Notion (markdown → blocks, вложенные задачи, шаблоны)
3. Разработка MCP-агента Confluence
4. Реализация семантического поиска в vector_store
5. Интеграция LLM/шаблонов в auto_fixer и test_generator
6. Расширение doc_generator (архитектура, API, связи)
7. Унификация интерфейсов MCP-агентов и экспортёров
8. Документирование архитектуры и best practices

## Расширяемость и best practices
- Добавление новых инструментов через `/tools/` (test_generator, auto_fixer, doc_generator, mcp_plane_exporter)
- Декларативное описание агентов и их возможностей в `agents.yaml`
- Поддержка новых типов задач, отчётов, бизнес-метрик
- Интеграция с внешними платформами (Plane.so, Notion, Confluence) через MCP-агентов:
  - Для Notion: поддержка экспорта спецификаций, задач, отчётов, автоматическая синхронизация статусов через Notion API.
  - Для Confluence: аналогичная интеграция через соответствующий MCP-агент.
  - Гибкая настройка маппинга данных и шаблонов страниц.
- Проведение архитектурного ревью и оптимизации кода на регулярной основе
- Покрытие новых модулей unit-тестами, предоставление шаблонов тестов для расширения
- Документирование архитектуры, точек расширения и best practices для разработчиков
- Использование итеративных циклов и автоматизации для повышения качества и скорости разработки